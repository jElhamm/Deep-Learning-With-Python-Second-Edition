{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 9**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This code provides a **modular and structured framework** for training a deep learning model to perform **image segmentation** on the **Oxford Pets dataset** using **TensorFlow/Keras**.\n",
        "\n",
        "- The `DatasetDownloader` class automates downloading and extracting the dataset. The `DataLoader` class handles **image preprocessing**, including resizing and converting images into numerical arrays.\n",
        "\n",
        "- The `SegmentationModel` class constructs a **U-Net-inspired** convolutional neural network for segmentation. The `Trainer` class manages model training with **checkpointing**, while the `Evaluator` class visualizes the model's predictions.\n",
        "\n",
        "- Finally, the `Plotter` class generates **training loss and validation loss curves**. This structured approach ensures **readability, modularity, and easy experimentation**, making it simple to extend the code for different segmentation tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import load_img, img_to_array, array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class DatasetDownloader:\n",
        "    @staticmethod\n",
        "    def download_dataset():\n",
        "        os.system(\"wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\")\n",
        "        os.system(\"wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\")\n",
        "        os.system(\"tar -xf images.tar.gz\")\n",
        "        os.system(\"tar -xf annotations.tar.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lx1G3oUPCicE"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, img_size=(200, 200)):\n",
        "        self.input_dir = \"images/\"\n",
        "        self.target_dir = \"annotations/trimaps/\"\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths, self.target_paths = self._load_paths()\n",
        "\n",
        "    def _load_paths(self):\n",
        "        input_img_paths = sorted(\n",
        "            [os.path.join(self.input_dir, fname)\n",
        "             for fname in os.listdir(self.input_dir)\n",
        "             if fname.endswith(\".jpg\")]\n",
        "        )\n",
        "        target_paths = sorted(\n",
        "            [os.path.join(self.target_dir, fname)\n",
        "             for fname in os.listdir(self.target_dir)\n",
        "             if fname.endswith(\".png\") and not fname.startswith(\".\")]\n",
        "        )\n",
        "        return input_img_paths, target_paths\n",
        "\n",
        "    def display_sample_image(self, index=9):\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(load_img(self.input_img_paths[index]))\n",
        "        plt.show()\n",
        "\n",
        "    def display_sample_mask(self, index=9):\n",
        "        img = img_to_array(load_img(self.target_paths[index], color_mode=\"grayscale\"))\n",
        "        normalized_array = (img.astype(\"uint8\") - 1) * 127\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(normalized_array[:, :, 0])\n",
        "        plt.show()\n",
        "\n",
        "    def load_dataset(self):\n",
        "        num_imgs = len(self.input_img_paths)\n",
        "        random.Random(1337).shuffle(self.input_img_paths)\n",
        "        random.Random(1337).shuffle(self.target_paths)\n",
        "\n",
        "        input_imgs = np.zeros((num_imgs,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        targets = np.zeros((num_imgs,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "\n",
        "        for i in range(num_imgs):\n",
        "            input_imgs[i] = self._path_to_input_image(self.input_img_paths[i])\n",
        "            targets[i] = self._path_to_target(self.target_paths[i])\n",
        "\n",
        "        return input_imgs, targets\n",
        "\n",
        "    def _path_to_input_image(self, path):\n",
        "        return img_to_array(load_img(path, target_size=self.img_size))\n",
        "\n",
        "    def _path_to_target(self, path):\n",
        "        img = img_to_array(load_img(path, target_size=self.img_size, color_mode=\"grayscale\"))\n",
        "        return img.astype(\"uint8\") - 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationModel:\n",
        "    @staticmethod\n",
        "    def build_model(img_size=(200, 200), num_classes=3):\n",
        "        inputs = keras.Input(shape=img_size + (3,))\n",
        "        x = layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "        # Convolutional layers\n",
        "        x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(256, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "        # Transpose Convolution layers (Upsampling)\n",
        "        x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "        x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "\n",
        "        # Output layer\n",
        "        outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "        return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "AMIFlb8B5DTO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_data, train_labels, val_data, val_labels):\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.train_labels = train_labels\n",
        "        self.val_data = val_data\n",
        "        self.val_labels = val_labels\n",
        "\n",
        "    def compile_model(self):\n",
        "        self.model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "    def train(self, epochs=50, batch_size=64):\n",
        "        callbacks = [keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\", save_best_only=True)]\n",
        "        history = self.model.fit(\n",
        "            self.train_data, self.train_labels,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(self.val_data, self.val_labels),\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "        return history.history"
      ],
      "metadata": {
        "id": "zI1CcA9A5Fxm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    @staticmethod\n",
        "    def evaluate_model(model, test_image):\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(array_to_img(test_image))\n",
        "        plt.show()\n",
        "\n",
        "        mask = model.predict(np.expand_dims(test_image, 0))[0]\n",
        "        Evaluator.display_mask(mask)\n",
        "\n",
        "    @staticmethod\n",
        "    def display_mask(pred):\n",
        "        mask = np.argmax(pred, axis=-1)\n",
        "        mask *= 127\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(mask)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "FjL17ZVC5Iw-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plotter:\n",
        "    @staticmethod\n",
        "    def plot_training_history(history):\n",
        "        epochs = range(1, len(history[\"loss\"]) + 1)\n",
        "        loss = history[\"loss\"]\n",
        "        val_loss = history[\"val_loss\"]\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "        plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "        plt.title(\"Training and validation loss\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "XSAgrObR5KwV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader()\n",
        "input_imgs, targets = data_loader.load_dataset()\n",
        "\n",
        "num_val_samples = 1000\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "model = SegmentationModel.build_model()\n",
        "trainer = Trainer(model, train_input_imgs, train_targets, val_input_imgs, val_targets)\n",
        "trainer.compile_model()\n",
        "history = trainer.train()\n",
        "\n",
        "Plotter.plot_training_history(history)\n",
        "model = keras.models.load_model(\"oxford_segmentation.keras\")\n",
        "Evaluator.evaluate_model(model, val_input_imgs[4])"
      ],
      "metadata": {
        "id": "QTv0Fv-sU796"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}