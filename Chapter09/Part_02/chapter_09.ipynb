{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 9**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This code provides a **modular and structured** approach to building, training, and evaluating a **deep learning model with residual connections** for the **Cats vs. Dogs classification task** using **TensorFlow/Keras**.\n",
        "\n",
        "- The `DatasetPreparer` class handles dataset organization, while `DataLoader` efficiently loads the data into TensorFlow datasets. The `ResidualBlock` class defines **residual connections** to enhance gradient flow and learning stability.\n",
        "\n",
        "- The `CNNModel` class constructs a **CNN architecture with batch normalization and data augmentation** to improve performance. The `Trainer` class manages training, and the `Evaluator` class evaluates the model on a test set.\n",
        "\n",
        "- Finally, the `Plotter` class visualizes **training accuracy and loss trends**. This design ensures **scalability, reusability, and ease of experimentation** for deep learning projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class DatasetPreparer:\n",
        "    def __init__(self, dataset_path=\"train\", new_base_dir=\"cats_vs_dogs_small\"):\n",
        "        self.original_dir = pathlib.Path(dataset_path)\n",
        "        self.new_base_dir = pathlib.Path(new_base_dir)\n",
        "\n",
        "    def make_subset(self, subset_name, start_index, end_index):\n",
        "        for category in (\"cat\", \"dog\"):\n",
        "            dir = self.new_base_dir / subset_name / category\n",
        "            os.makedirs(dir, exist_ok=True)\n",
        "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "            for fname in fnames:\n",
        "                shutil.copyfile(src=self.original_dir / fname, dst=dir / fname)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.make_subset(\"train\", start_index=0, end_index=1000)\n",
        "        self.make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "        self.make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lx1G3oUPCicE"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock:\n",
        "    @staticmethod\n",
        "    def build_residual_block(x, filters, pooling=False):\n",
        "        residual = x\n",
        "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "        if pooling:\n",
        "            x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "            residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(residual)\n",
        "        elif filters != residual.shape[-1]:\n",
        "            residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel:\n",
        "    @staticmethod\n",
        "    def build_model(img_size=(180, 180, 3), use_data_augmentation=True):\n",
        "        inputs = keras.Input(shape=img_size)\n",
        "\n",
        "        if use_data_augmentation:\n",
        "            data_augmentation = keras.Sequential([\n",
        "                layers.RandomFlip(\"horizontal\"),\n",
        "                layers.RandomRotation(0.1),\n",
        "                layers.RandomZoom(0.2),\n",
        "            ])\n",
        "            x = data_augmentation(inputs)\n",
        "        else:\n",
        "            x = inputs\n",
        "\n",
        "        x = layers.Rescaling(1./255)(x)\n",
        "        x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "        # افزودن Residual Blocks\n",
        "        for size in [32, 64, 128, 256, 512]:\n",
        "            residual = x\n",
        "\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Activation(\"relu\")(x)\n",
        "            x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Activation(\"relu\")(x)\n",
        "            x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "            x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "            residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "            x = layers.add([x, residual])\n",
        "\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "        return keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "AMIFlb8B5DTO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_data, val_data):\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "\n",
        "    def compile_model(self):\n",
        "        self.model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "    def train(self, epochs=100):\n",
        "        history = self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.val_data\n",
        "        )\n",
        "        return history.history"
      ],
      "metadata": {
        "id": "zI1CcA9A5Fxm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    @staticmethod\n",
        "    def evaluate_model(model, test_data):\n",
        "        results = model.evaluate(test_data)\n",
        "        print(f\"Test Accuracy: {results[1]:.3f}\")\n",
        "        return results"
      ],
      "metadata": {
        "id": "FjL17ZVC5Iw-"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plotter:\n",
        "    @staticmethod\n",
        "    def plot_training_history(history):\n",
        "        epochs = range(1, len(history[\"loss\"]) + 1)\n",
        "        loss = history[\"loss\"]\n",
        "        val_loss = history[\"val_loss\"]\n",
        "        accuracy = history[\"accuracy\"]\n",
        "        val_accuracy = history[\"val_accuracy\"]\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "        plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "        plt.title(\"Training and validation accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "        plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "        plt.title(\"Training and validation loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "XSAgrObR5KwV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_preparer = DatasetPreparer()\n",
        "dataset_preparer.prepare_data()\n",
        "\n",
        "data_loader = DataLoader()\n",
        "train_dataset, validation_dataset, test_dataset = data_loader.load_data()\n",
        "\n",
        "model = CNNModel.build_model()\n",
        "trainer = Trainer(model, train_dataset, validation_dataset)\n",
        "trainer.compile_model()\n",
        "history = trainer.train()\n",
        "\n",
        "Plotter.plot_training_history(history)\n",
        "Evaluator.evaluate_model(model, test_dataset)"
      ],
      "metadata": {
        "id": "S-Nq_OI-kF0x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}