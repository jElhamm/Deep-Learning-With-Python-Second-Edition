{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 12**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This implementation of **Neural Style Transfer (NST)** is structured as a class-based system using **TensorFlow and Keras**, making it modular and reusable.\n",
        "\n",
        "- The `NeuralStyleTransfer` class handles image preprocessing, feature extraction using **VGG19**, and loss computation, including **content loss, style loss (using Gram matrices), and total variation loss** for smoothness.\n",
        "\n",
        "- The optimization process is implemented using **gradient descent with an exponentially decaying learning rate**, refining the combination image over multiple iterations. The model extracts key features from both the content and style images, blending them to generate an artistic transformation.\n",
        "\n",
        "- The output is saved at regular intervals, allowing visualization of the NST process. This structured approach improves code maintainability, making it easier to experiment with different hyperparameters and extend the functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class NeuralStyleTransfer:\n",
        "    def __init__(self, base_image_url, style_image_url, img_height=400, style_weight=1e-6, content_weight=2.5e-8, tv_weight=1e-6):\n",
        "        \"\"\"\n",
        "            Initializes the Neural Style Transfer model with given parameters.\n",
        "\n",
        "            - base_image_url: URL of the base image\n",
        "            - style_image_url: URL of the style reference image\n",
        "            - img_height: Height of the processed images\n",
        "            - style_weight: Weight for style loss\n",
        "            - content_weight: Weight for content loss\n",
        "            - tv_weight: Weight for total variation loss\n",
        "        \"\"\"\n",
        "        self.base_image_path = keras.utils.get_file(\"base.jpg\", origin=base_image_url)\n",
        "        self.style_reference_image_path = keras.utils.get_file(\"style.jpg\", origin=style_image_url)\n",
        "\n",
        "        original_width, original_height = keras.utils.load_img(self.base_image_path).size\n",
        "        self.img_height = img_height\n",
        "        self.img_width = round(original_width * img_height / original_height)\n",
        "\n",
        "        self.style_weight = style_weight\n",
        "        self.content_weight = content_weight\n",
        "        self.tv_weight = tv_weight\n",
        "\n",
        "        self.model = keras.applications.vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
        "        self.feature_extractor = self.build_feature_extractor()\n",
        "\n",
        "        self.style_layer_names = [\n",
        "            \"block1_conv1\",\n",
        "            \"block2_conv1\",\n",
        "            \"block3_conv1\",\n",
        "            \"block4_conv1\",\n",
        "            \"block5_conv1\",\n",
        "        ]\n",
        "        self.content_layer_name = \"block5_conv2\"\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"\n",
        "            Prepares an image for use with the VGG19 model.\n",
        "        \"\"\"\n",
        "        img = keras.utils.load_img(image_path, target_size=(self.img_height, self.img_width))\n",
        "        img = keras.utils.img_to_array(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = keras.applications.vgg19.preprocess_input(img)\n",
        "        return img\n",
        "\n",
        "    def deprocess_image(self, img):\n",
        "        \"\"\"\n",
        "            Converts a processed image back to a viewable format.\n",
        "        \"\"\"\n",
        "        img = img.reshape((self.img_height, self.img_width, 3))\n",
        "        img[:, :, 0] += 103.939\n",
        "        img[:, :, 1] += 116.779\n",
        "        img[:, :, 2] += 123.68\n",
        "        img = img[:, :, ::-1]\n",
        "        img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "        return img\n",
        "\n",
        "    def build_feature_extractor(self):\n",
        "        \"\"\"\n",
        "            Builds a feature extractor model from VGG19.\n",
        "        \"\"\"\n",
        "        outputs_dict = {layer.name: layer.output for layer in self.model.layers}\n",
        "        return keras.Model(inputs=self.model.inputs, outputs=outputs_dict)\n",
        "\n",
        "    @staticmethod\n",
        "    def content_loss(base_img, combination_img):\n",
        "        return tf.reduce_sum(tf.square(combination_img - base_img))\n",
        "\n",
        "    @staticmethod\n",
        "    def gram_matrix(x):\n",
        "        x = tf.transpose(x, (2, 0, 1))\n",
        "        features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "        return tf.matmul(features, tf.transpose(features))\n",
        "\n",
        "    def style_loss(self, style_img, combination_img):\n",
        "        \"\"\"\n",
        "            Computes the style loss using Gram matrices.\n",
        "        \"\"\"\n",
        "        S = self.gram_matrix(style_img)\n",
        "        C = self.gram_matrix(combination_img)\n",
        "        channels = 3\n",
        "        size = self.img_height * self.img_width\n",
        "        return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
        "\n",
        "    def total_variation_loss(self, x):\n",
        "        \"\"\"\n",
        "            Computes the total variation loss for smoothness.\n",
        "        \"\"\"\n",
        "        a = tf.square(x[:, : self.img_height - 1, : self.img_width - 1, :] - x[:, 1:, : self.img_width - 1, :])\n",
        "        b = tf.square(x[:, : self.img_height - 1, : self.img_width - 1, :] - x[:, : self.img_height - 1, 1:, :])\n",
        "        return tf.reduce_sum(tf.pow(a + b, 1.25))\n",
        "\n",
        "    def compute_loss(self, combination_image, base_image, style_reference_image):\n",
        "        \"\"\"\n",
        "            Computes the total loss for optimization.\n",
        "        \"\"\"\n",
        "        input_tensor = tf.concat([base_image, style_reference_image, combination_image], axis=0)\n",
        "        features = self.feature_extractor(input_tensor)\n",
        "\n",
        "        loss = tf.zeros(shape=())\n",
        "        layer_features = features[self.content_layer_name]\n",
        "        base_image_features = layer_features[0, :, :, :]\n",
        "        combination_features = layer_features[2, :, :, :]\n",
        "        loss += self.content_weight * self.content_loss(base_image_features, combination_features)\n",
        "\n",
        "        for layer_name in self.style_layer_names:\n",
        "            layer_features = features[layer_name]\n",
        "            style_reference_features = layer_features[1, :, :, :]\n",
        "            combination_features = layer_features[2, :, :, :]\n",
        "            loss += (self.style_weight / len(self.style_layer_names)) * self.style_loss(style_reference_features, combination_features)\n",
        "\n",
        "        loss += self.tv_weight * self.total_variation_loss(combination_image)\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss_and_grads(self, combination_image, base_image, style_reference_image):\n",
        "        \"\"\"\n",
        "            Computes gradients for optimization.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.compute_loss(combination_image, base_image, style_reference_image)\n",
        "        grads = tape.gradient(loss, combination_image)\n",
        "        return loss, grads\n",
        "\n",
        "    def train(self, iterations=4000, learning_rate=100.0, decay_steps=100, decay_rate=0.96):\n",
        "        \"\"\"\n",
        "            Trains the neural style transfer model.\n",
        "        \"\"\"\n",
        "        optimizer = keras.optimizers.SGD(\n",
        "            keras.optimizers.schedules.ExponentialDecay(\n",
        "                initial_learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate\n",
        "            )\n",
        "        )\n",
        "\n",
        "        base_image = self.preprocess_image(self.base_image_path)\n",
        "        style_reference_image = self.preprocess_image(self.style_reference_image_path)\n",
        "        combination_image = tf.Variable(self.preprocess_image(self.base_image_path))\n",
        "\n",
        "        for i in range(1, iterations + 1):\n",
        "            loss, grads = self.compute_loss_and_grads(combination_image, base_image, style_reference_image)\n",
        "            optimizer.apply_gradients([(grads, combination_image)])\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Iteration {i}: loss={loss:.2f}\")\n",
        "                img = self.deprocess_image(combination_image.numpy())\n",
        "                fname = f\"combination_image_at_iteration_{i}.png\"\n",
        "                keras.utils.save_img(fname, img)\n",
        "\n",
        "        print(\"Training complete! Final image saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nst = NeuralStyleTransfer(\n",
        "    base_image_url=\"https://img-datasets.s3.amazonaws.com/sf.jpg\",\n",
        "    style_image_url=\"https://img-datasets.s3.amazonaws.com/starry_night.jpg\"\n",
        ")\n",
        "nst.train()"
      ],
      "metadata": {
        "id": "6mitfoIAJY0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}