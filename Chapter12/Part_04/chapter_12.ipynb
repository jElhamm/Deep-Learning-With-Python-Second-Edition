{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 12**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This implementation of **Neural Style Transfer (NST)** is structured as a class-based system using **TensorFlow and Keras**, making it modular and reusable.\n",
        "\n",
        "- The `NeuralStyleTransfer` class handles image preprocessing, feature extraction using **VGG19**, and loss computation, including **content loss, style loss (using Gram matrices), and total variation loss** for smoothness.\n",
        "\n",
        "- The optimization process is implemented using **gradient descent with an exponentially decaying learning rate**, refining the combination image over multiple iterations. The model extracts key features from both the content and style images, blending them to generate an artistic transformation.\n",
        "\n",
        "- The output is saved at regular intervals, allowing visualization of the NST process. This structured approach improves code maintainability, making it easier to experiment with different hyperparameters and extend the functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class Encoder(keras.Model):\n",
        "    \"\"\"Defines the encoder network of the Variational Autoencoder (VAE).\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_layers = keras.Sequential([\n",
        "            layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "            layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(16, activation=\"relu\"),\n",
        "        ])\n",
        "        self.z_mean = layers.Dense(latent_dim, name=\"z_mean\")\n",
        "        self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv_layers(inputs)\n",
        "        return self.z_mean(x), self.z_log_var(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler(layers.Layer):\n",
        "    \"\"\"Sampling layer to generate latent variables using reparameterization trick.\"\"\"\n",
        "\n",
        "    def call(self, z_mean, z_log_var):\n",
        "        batch_size = tf.shape(z_mean)[0]\n",
        "        z_size = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch_size, z_size))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "6mitfoIAJY0r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.Model):\n",
        "    \"\"\"Defines the decoder network of the Variational Autoencoder (VAE).\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.dense = layers.Dense(7 * 7 * 64, activation=\"relu\")\n",
        "        self.reshape = layers.Reshape((7, 7, 64))\n",
        "        self.conv_transpose_layers = keras.Sequential([\n",
        "            layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "            layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "            layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\"),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense(inputs)\n",
        "        x = self.reshape(x)\n",
        "        return self.conv_transpose_layers(x)"
      ],
      "metadata": {
        "id": "qr8jz4GeLVbT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    \"\"\"Defines the Variational Autoencoder (VAE) model.\"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sampler = Sampler()\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var = self.encoder(data)\n",
        "            z = self.sampler(z_mean, z_log_var)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2))\n",
        "            )\n",
        "            kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"total_loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "5KU0n2MpLXsb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAETrainer:\n",
        "    \"\"\"Handles training and visualization for the Variational Autoencoder (VAE).\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=2, batch_size=128, epochs=30):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim)\n",
        "        self.vae = VAE(self.encoder, self.decoder)\n",
        "        self.vae.compile(optimizer=keras.optimizers.Adam(), run_eagerly=True)\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Loads the MNIST dataset and preprocesses it.\"\"\"\n",
        "        (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "        mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "        mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "        return mnist_digits\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Trains the VAE model.\"\"\"\n",
        "        data = self.load_data()\n",
        "        self.vae.fit(data, epochs=self.epochs, batch_size=self.batch_size)\n",
        "\n",
        "    def visualize_latent_space(self, n=30, digit_size=28):\n",
        "        \"\"\"Generates and visualizes digits from the latent space.\"\"\"\n",
        "        figure = np.zeros((digit_size * n, digit_size * n))\n",
        "        grid_x = np.linspace(-1, 1, n)\n",
        "        grid_y = np.linspace(-1, 1, n)[::-1]\n",
        "\n",
        "        for i, yi in enumerate(grid_y):\n",
        "            for j, xi in enumerate(grid_x):\n",
        "                z_sample = np.array([[xi, yi]])\n",
        "                x_decoded = self.vae.decoder.predict(z_sample)\n",
        "                digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "                figure[\n",
        "                    i * digit_size: (i + 1) * digit_size,\n",
        "                    j * digit_size: (j + 1) * digit_size,\n",
        "                ] = digit\n",
        "\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        start_range = digit_size // 2\n",
        "        end_range = n * digit_size + start_range\n",
        "        pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "        sample_range_x = np.round(grid_x, 1)\n",
        "        sample_range_y = np.round(grid_y, 1)\n",
        "        plt.xticks(pixel_range, sample_range_x)\n",
        "        plt.yticks(pixel_range, sample_range_y)\n",
        "        plt.xlabel(\"z[0]\")\n",
        "        plt.ylabel(\"z[1]\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(figure, cmap=\"Greys_r\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "DkfZR6EULaJ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae_trainer = VAETrainer()\n",
        "vae_trainer.train()\n",
        "vae_trainer.visualize_latent_space()"
      ],
      "metadata": {
        "id": "Mkmfv2E8LxYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}