{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 12**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- The **DeepDream** implementation in this code uses **InceptionV3** to enhance image details by amplifying patterns detected by specific layers. The process begins with loading and preprocessing an image, followed by extracting features from key convolutional layers to compute a loss function.\n",
        "\n",
        "- Using **gradient ascent**, the model enhances patterns in the image by iteratively modifying pixel values to maximize activations in selected layers. The technique is applied across multiple scales (octaves) to progressively\n",
        "\n",
        "- refine details, ensuring finer textures and avoiding excessive artifacts. Finally, the processed image is de-normalized and saved, resulting in a **dream-like visual effect** that highlights intricate patterns and textures within the image.\n",
        "\n",
        "- The code is structured into a **class-based** design for better modularity and reusability, allowing easy integration into larger deep-learning projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import inception_v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class DeepDream:\n",
        "    def __init__(self, image_path, layer_settings=None):\n",
        "        self.image_path = image_path\n",
        "        self.model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "        self.layer_settings = layer_settings or {\n",
        "            \"mixed4\": 1.0,\n",
        "            \"mixed5\": 1.5,\n",
        "            \"mixed6\": 2.0,\n",
        "            \"mixed7\": 2.5,\n",
        "        }\n",
        "\n",
        "        self.feature_extractor = self.build_feature_extractor()\n",
        "\n",
        "    def build_feature_extractor(self):\n",
        "        outputs_dict = {\n",
        "            layer_name: self.model.get_layer(name=layer_name).output\n",
        "            for layer_name in self.layer_settings.keys()\n",
        "        }\n",
        "        return keras.Model(inputs=self.model.input, outputs=outputs_dict)\n",
        "\n",
        "    def preprocess_image(self):\n",
        "        img = keras.utils.load_img(self.image_path)\n",
        "        img = keras.utils.img_to_array(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = keras.applications.inception_v3.preprocess_input(img)\n",
        "        return img\n",
        "\n",
        "    def deprocess_image(self, img):\n",
        "        img = img.reshape((img.shape[1], img.shape[2], 3))\n",
        "        img /= 2.0\n",
        "        img += 0.5\n",
        "        img *= 255.\n",
        "        return np.clip(img, 0, 255).astype(\"uint8\")\n",
        "\n",
        "    def compute_loss(self, input_image):\n",
        "        features = self.feature_extractor(input_image)\n",
        "        loss = tf.zeros(shape=())\n",
        "\n",
        "        for layer_name, coeff in self.layer_settings.items():\n",
        "            activation = features[layer_name]\n",
        "            loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :]))\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def gradient_ascent_step(self, image, learning_rate):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(image)\n",
        "            loss = self.compute_loss(image)\n",
        "        grads = tape.gradient(loss, image)\n",
        "        grads = tf.math.l2_normalize(grads)\n",
        "        image += learning_rate * grads\n",
        "        return loss, image\n",
        "\n",
        "    def gradient_ascent_loop(self, image, iterations, learning_rate, max_loss=None):\n",
        "        for i in range(iterations):\n",
        "            loss, image = self.gradient_ascent_step(image, learning_rate)\n",
        "            if max_loss is not None and loss > max_loss:\n",
        "                break\n",
        "            print(f\"... Loss value at step {i}: {loss:.2f}\")\n",
        "        return image\n",
        "\n",
        "    def deep_dream(self, step=20., num_octave=3, octave_scale=1.4, iterations=30, max_loss=15.):\n",
        "        original_img = self.preprocess_image()\n",
        "        original_shape = original_img.shape[1:3]\n",
        "\n",
        "        successive_shapes = [original_shape]\n",
        "        for i in range(1, num_octave):\n",
        "            shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
        "            successive_shapes.append(shape)\n",
        "        successive_shapes = successive_shapes[::-1]\n",
        "\n",
        "        shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])\n",
        "        img = tf.identity(original_img)\n",
        "\n",
        "        for i, shape in enumerate(successive_shapes):\n",
        "            print(f\"Processing octave {i+1} with shape {shape}\")\n",
        "            img = tf.image.resize(img, shape)\n",
        "            img = self.gradient_ascent_loop(img, iterations=iterations, learning_rate=step, max_loss=max_loss)\n",
        "\n",
        "            upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)\n",
        "            same_size_original = tf.image.resize(original_img, shape)\n",
        "            lost_detail = same_size_original - upscaled_shrunk_original_img\n",
        "            img += lost_detail\n",
        "            shrunk_original_img = tf.image.resize(original_img, shape)\n",
        "\n",
        "        final_image = self.deprocess_image(img.numpy())\n",
        "        keras.utils.save_img(\"dream.png\", final_image)\n",
        "        return final_image\n",
        "\n",
        "    def display_image(self, image):\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(image)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = keras.utils.get_file(\"coast.jpg\", origin=\"https://img-datasets.s3.amazonaws.com/coast.jpg\")\n",
        "deep_dream = DeepDream(image_path)\n",
        "\n",
        "dream_image = deep_dream.deep_dream()\n",
        "deep_dream.display_image(dream_image)"
      ],
      "metadata": {
        "id": "0FzDvbfUHOGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}