{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 7**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This code provides a **modular and structured approach** to defining, training, and evaluating machine learning models using **TensorFlow/Keras**. The `BaseModel` class creates simple sequential models, while `MultiInputModel` handles multi-input architectures for complex data.\n",
        "\n",
        "- The `Trainer` class manages model training, and the `Evaluator` class handles performance evaluation. Advanced custom models, such as `CustomerTicketModel` and `Classifier`, allow for tailored architectures, while `RootMeanSquaredError` demonstrates the implementation of a **custom metric**.\n",
        "\n",
        "- The `CallbacksManager` class optimizes training with **early stopping and model checkpointing**, and `Plotter` visualizes training performance. This design ensures **reusability, scalability, and clean code structure**, making it easier to experiment with different models and datasets efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class BaseModel:\n",
        "    def __init__(self, input_shape, output_units, hidden_units=64, activation=\"relu\", output_activation=\"softmax\"):\n",
        "        self.model = keras.Sequential([\n",
        "            layers.Dense(hidden_units, activation=activation, input_shape=(input_shape,)),\n",
        "            layers.Dense(output_units, activation=output_activation)\n",
        "        ])\n",
        "\n",
        "    def build_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lx1G3oUPCicE"
      },
      "outputs": [],
      "source": [
        "class MultiInputModel:\n",
        "    def __init__(self, vocabulary_size, num_tags, num_departments):\n",
        "        title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
        "        text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
        "        tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
        "\n",
        "        features = layers.Concatenate()([title, text_body, tags])\n",
        "        features = layers.Dense(64, activation=\"relu\")(features)\n",
        "\n",
        "        priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
        "        department = layers.Dense(num_departments, activation=\"softmax\", name=\"department\")(features)\n",
        "\n",
        "        self.model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])\n",
        "\n",
        "    def build_model(self):\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_data, train_labels, validation_split=0.2):\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.train_labels = train_labels\n",
        "        self.validation_split = validation_split\n",
        "\n",
        "    def compile_model(self, loss_function=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"]):\n",
        "        self.model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
        "\n",
        "    def train(self, epochs=10, batch_size=128):\n",
        "        history = self.model.fit(\n",
        "            self.train_data, self.train_labels,\n",
        "            epochs=epochs, batch_size=batch_size,\n",
        "            validation_split=self.validation_split\n",
        "        )\n",
        "        return history.history"
      ],
      "metadata": {
        "id": "AMIFlb8B5DTO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    @staticmethod\n",
        "    def evaluate(model, test_data, test_labels):\n",
        "        results = model.evaluate(test_data, test_labels)\n",
        "        print(f\"Test results: {results}\")\n",
        "        return results"
      ],
      "metadata": {
        "id": "zI1CcA9A5Fxm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomerTicketModel(keras.Model):\n",
        "    def __init__(self, num_departments):\n",
        "        super().__init__()\n",
        "        self.concat_layer = layers.Concatenate()\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.department_classifier = layers.Dense(num_departments, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        title = inputs[\"title\"]\n",
        "        text_body = inputs[\"text_body\"]\n",
        "        tags = inputs[\"tags\"]\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags])\n",
        "        features = self.mixing_layer(features)\n",
        "        priority = self.priority_scorer(features)\n",
        "        department = self.department_classifier(features)\n",
        "        return priority, department"
      ],
      "metadata": {
        "id": "FjL17ZVC5Iw-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(keras.Model):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.dense = layers.Dense(num_classes, activation=\"softmax\" if num_classes > 2 else \"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)"
      ],
      "metadata": {
        "id": "XSAgrObR5KwV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        num_samples = tf.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0)"
      ],
      "metadata": {
        "id": "GQNic0Q35MqF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CallbacksManager:\n",
        "    @staticmethod\n",
        "    def get_callbacks():\n",
        "        return [\n",
        "            keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2),\n",
        "            keras.callbacks.ModelCheckpoint(filepath=\"checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
        "        ]"
      ],
      "metadata": {
        "id": "qsUcFFwE5Qhv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plotter:\n",
        "    @staticmethod\n",
        "    def plot_history(history, metric=\"accuracy\"):\n",
        "        epochs = range(1, len(history[metric]) + 1)\n",
        "        plt.plot(epochs, history[metric], \"bo\", label=f\"Training {metric}\")\n",
        "        plt.plot(epochs, history[f\"val_{metric}\"], \"b\", label=f\"Validation {metric}\")\n",
        "        plt.title(f\"Training and validation {metric}\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ZsRxYFGf5SY2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 1280\n",
        "vocabulary_size = 10000\n",
        "num_tags = 100\n",
        "num_departments = 4\n",
        "\n",
        "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
        "\n",
        "priority_data = np.random.random(size=(num_samples, 1))\n",
        "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))"
      ],
      "metadata": {
        "id": "nq_PmVZs5Upu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_input_model = MultiInputModel(vocabulary_size, num_tags, num_departments).build_model()\n",
        "multi_input_model.compile(optimizer=\"rmsprop\",\n",
        "                          loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "                          metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
        "\n",
        "multi_input_model.fit([title_data, text_body_data, tags_data],\n",
        "                      [priority_data, department_data], epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS6hp3qWLTck",
        "outputId": "7c62a055-1945-4e89-8778-9fe88b83cb6d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - department_accuracy: 0.2864 - department_loss: 38.0661 - loss: 38.3769 - priority_loss: 0.3108 - priority_mean_absolute_error: 0.4766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ddd11b4a0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_model = BaseModel(input_shape=3, output_units=10).build_model()\n",
        "trainer = Trainer(basic_model, title_data, priority_data)\n",
        "trainer.compile_model(loss_function=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
        "history = trainer.train(epochs=5)\n",
        "Plotter.plot_history(history, \"accuracy\")"
      ],
      "metadata": {
        "id": "FM7RNuNbL7Yj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}