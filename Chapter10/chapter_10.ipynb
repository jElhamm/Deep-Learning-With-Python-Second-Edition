{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This code provides a **modular and structured** approach to training deep learning models for **time series forecasting** using the **Jena Climate dataset**.\n",
        "\n",
        "- The `DatasetDownloader` handles dataset retrieval, while `DataLoader` preprocesses the data by normalizing features. The `TimeSeriesGenerator` converts the raw dataset into structured time series sequences.\n",
        "\n",
        "- The `BaselineEvaluator` implements a **Naïve Method** for benchmarking performance. The `ModelBuilder` constructs various models, including **Dense, CNN, and LSTM architectures**, for forecasting temperature variations.\n",
        "\n",
        "- The `Trainer` class manages **model training and checkpointing**, while the `Plotter` visualizes **training and validation MAE trends**. This **modular design ensures scalability, reusability, and efficient experimentation**, making it ideal for time series forecasting applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class DatasetDownloader:\n",
        "    @staticmethod\n",
        "    def download_dataset():\n",
        "        os.system(\"wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\")\n",
        "        os.system(\"unzip jena_climate_2009_2016.csv.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lx1G3oUPCicE"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, file_path=\"jena_climate_2009_2016.csv\"):\n",
        "        self.file_path = file_path\n",
        "        self.raw_data, self.temperature, self.mean, self.std = self._load_and_preprocess_data()\n",
        "\n",
        "    def _load_and_preprocess_data(self):\n",
        "        with open(self.file_path) as f:\n",
        "            data = f.read()\n",
        "\n",
        "        lines = data.split(\"\\n\")[1:]  # حذف Header\n",
        "        raw_data = np.zeros((len(lines), 14))  # 14 ویژگی به جز دما\n",
        "        temperature = np.zeros((len(lines),))\n",
        "\n",
        "        for i, line in enumerate(lines):\n",
        "            values = [float(x) for x in line.split(\",\")[1:]]\n",
        "            temperature[i] = values[1]  # مقدار دما\n",
        "            raw_data[i, :] = values[:]\n",
        "\n",
        "        # نرمال‌سازی داده‌ها\n",
        "        mean = raw_data[:int(0.5 * len(raw_data))].mean(axis=0)\n",
        "        std = raw_data[:int(0.5 * len(raw_data))].std(axis=0)\n",
        "        raw_data = (raw_data - mean) / std\n",
        "\n",
        "        return raw_data, temperature, mean, std"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesGenerator:\n",
        "    def __init__(self, raw_data, temperature, sampling_rate=6, sequence_length=120, delay=144):\n",
        "        self.raw_data = raw_data\n",
        "        self.temperature = temperature\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.sequence_length = sequence_length\n",
        "        self.delay = delay\n",
        "        self.batch_size = 256\n",
        "\n",
        "    def create_datasets(self, train_split=0.5, val_split=0.25):\n",
        "        num_train_samples = int(train_split * len(self.raw_data))\n",
        "        num_val_samples = int(val_split * len(self.raw_data))\n",
        "\n",
        "        train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "            self.raw_data[:-self.delay],\n",
        "            targets=self.temperature[self.delay:],\n",
        "            sampling_rate=self.sampling_rate,\n",
        "            sequence_length=self.sequence_length,\n",
        "            shuffle=True,\n",
        "            batch_size=self.batch_size,\n",
        "            start_index=0,\n",
        "            end_index=num_train_samples\n",
        "        )\n",
        "\n",
        "        val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "            self.raw_data[:-self.delay],\n",
        "            targets=self.temperature[self.delay:],\n",
        "            sampling_rate=self.sampling_rate,\n",
        "            sequence_length=self.sequence_length,\n",
        "            shuffle=True,\n",
        "            batch_size=self.batch_size,\n",
        "            start_index=num_train_samples,\n",
        "            end_index=num_train_samples + num_val_samples\n",
        "        )\n",
        "\n",
        "        test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "            self.raw_data[:-self.delay],\n",
        "            targets=self.temperature[self.delay:],\n",
        "            sampling_rate=self.sampling_rate,\n",
        "            sequence_length=self.sequence_length,\n",
        "            shuffle=True,\n",
        "            batch_size=self.batch_size,\n",
        "            start_index=num_train_samples + num_val_samples\n",
        "        )\n",
        "\n",
        "        return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "AMIFlb8B5DTO"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineEvaluator:\n",
        "    def __init__(self, dataset, mean, std):\n",
        "        self.dataset = dataset\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def evaluate_naive_method(self):\n",
        "        total_abs_err = 0.\n",
        "        samples_seen = 0\n",
        "        for samples, targets in self.dataset:\n",
        "            preds = samples[:, -1, 1] * self.std[1] + self.mean[1]\n",
        "            total_abs_err += np.sum(np.abs(preds - targets))\n",
        "            samples_seen += samples.shape[0]\n",
        "        return total_abs_err / samples_seen"
      ],
      "metadata": {
        "id": "zI1CcA9A5Fxm"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBuilder:\n",
        "    @staticmethod\n",
        "    def build_dense_model(input_shape):\n",
        "        inputs = keras.Input(shape=input_shape)\n",
        "        x = layers.Flatten()(inputs)\n",
        "        x = layers.Dense(16, activation=\"relu\")(x)\n",
        "        outputs = layers.Dense(1)(x)\n",
        "        return keras.Model(inputs, outputs)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_cnn_model(input_shape):\n",
        "        inputs = keras.Input(shape=input_shape)\n",
        "        x = layers.Conv1D(8, 24, activation=\"relu\")(inputs)\n",
        "        x = layers.MaxPooling1D(2)(x)\n",
        "        x = layers.Conv1D(8, 12, activation=\"relu\")(x)\n",
        "        x = layers.MaxPooling1D(2)(x)\n",
        "        x = layers.Conv1D(8, 6, activation=\"relu\")(x)\n",
        "        x = layers.GlobalAveragePooling1D()(x)\n",
        "        outputs = layers.Dense(1)(x)\n",
        "        return keras.Model(inputs, outputs)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_lstm_model(input_shape):\n",
        "        inputs = keras.Input(shape=input_shape)\n",
        "        x = layers.LSTM(16)(inputs)\n",
        "        outputs = layers.Dense(1)(x)\n",
        "        return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "FjL17ZVC5Iw-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_data, val_data, model_name):\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def compile_model(self):\n",
        "        self.model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        callbacks = [keras.callbacks.ModelCheckpoint(f\"{self.model_name}.keras\", save_best_only=True)]\n",
        "        history = self.model.fit(self.train_data, epochs=epochs, validation_data=self.val_data, callbacks=callbacks)\n",
        "        return history.history\n"
      ],
      "metadata": {
        "id": "XSAgrObR5KwV"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plotter:\n",
        "    @staticmethod\n",
        "    def plot_training_history(history):\n",
        "        epochs = range(1, len(history[\"mae\"]) + 1)\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, history[\"mae\"], \"bo\", label=\"Training MAE\")\n",
        "        plt.plot(epochs, history[\"val_mae\"], \"b\", label=\"Validation MAE\")\n",
        "        plt.title(\"Training and Validation MAE\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "EPJQ7IVPo3da"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader()\n",
        "train_data, val_data, test_data = TimeSeriesGenerator(data_loader.raw_data, data_loader.temperature).create_datasets()\n",
        "\n",
        "baseline = BaselineEvaluator(val_data, data_loader.mean, data_loader.std)\n",
        "print(f\"Validation MAE (Naïve Method): {baseline.evaluate_naive_method():.2f}\")\n",
        "\n",
        "dense_model = ModelBuilder.build_dense_model(input_shape=(120, 14))\n",
        "trainer = Trainer(dense_model, train_data, val_data, \"jena_dense\")\n",
        "trainer.compile_model()\n",
        "dense_history = trainer.train()\n",
        "\n",
        "Plotter.plot_training_history(dense_history)"
      ],
      "metadata": {
        "id": "Jk5-2nJkpKEw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}