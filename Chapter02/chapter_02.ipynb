{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRAEtvJ_6OT"
      },
      "source": [
        "# **Deep Learning With Python  -  CHAPTER 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HE2uMKK_7Qp"
      },
      "source": [
        "- This code creates a fully organized system for loading, processing, training, and evaluating a neural network model on the **MNIST** dataset.\n",
        "\n",
        "- The `DataLoader` class loads and preprocesses image data, while the `NeuralNetwork` class defines a **deep neural network** with two layers. The `Trainer` class handles model training using the processed data, whereas the `Evaluator` class assesses model performance and makes predictions.\n",
        "\n",
        "- To optimize data processing, the `BatchGenerator` class manages **batching**, and the `MatrixOperations` class performs matrix operations such as **addition, multiplication, and ReLU activation**.\n",
        "\n",
        "- Additionally, the `GradientComputation` class uses `GradientTape` to compute gradients. This **modular and flexible** structure allows for easy expansion and adaptation for more complex models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oqNg9frRCBgk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7HHCQEtlu8Pg"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.train_images, self.train_labels, self.test_images, self.test_labels = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        (train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "        return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        self.train_images = self.train_images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "        self.test_images = self.test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "\n",
        "    def get_data(self):\n",
        "        return (self.train_images, self.train_labels), (self.test_images, self.test_labels)\n",
        "\n",
        "    def show_sample(self, index=0):\n",
        "        plt.imshow(self.train_images[index].reshape(28, 28), cmap=plt.cm.binary)\n",
        "        plt.show()\n",
        "        print(f\"Label: {self.train_labels[index]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lx1G3oUPCicE"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(512, activation=\"relu\", input_shape=(28*28,)),\n",
        "            layers.Dense(10, activation=\"softmax\")\n",
        "        ])\n",
        "        model.compile(optimizer=\"rmsprop\",\n",
        "                      loss=\"sparse_categorical_crossentropy\",\n",
        "                      metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_images, train_labels):\n",
        "        self.model = model\n",
        "        self.train_images = train_images\n",
        "        self.train_labels = train_labels\n",
        "\n",
        "    def train(self, epochs=5, batch_size=128):\n",
        "        self.model.fit(self.train_images, self.train_labels, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "AMIFlb8B5DTO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, test_images, test_labels):\n",
        "        self.model = model\n",
        "        self.test_images = test_images\n",
        "        self.test_labels = test_labels\n",
        "\n",
        "    def evaluate(self):\n",
        "        test_loss, test_acc = self.model.evaluate(self.test_images, self.test_labels)\n",
        "        print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "    def predict(self, index=0):\n",
        "        test_sample = self.test_images[index:index+1]\n",
        "        predictions = self.model.predict(test_sample)\n",
        "        predicted_label = np.argmax(predictions[0])\n",
        "        confidence = predictions[0][predicted_label]\n",
        "        print(f\"Predicted Label: {predicted_label}, Confidence: {confidence:.2f}\")\n",
        "        return predicted_label"
      ],
      "metadata": {
        "id": "zI1CcA9A5Fxm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixOperations:\n",
        "    @staticmethod\n",
        "    def naive_relu(x):\n",
        "        assert len(x.shape) == 2\n",
        "        x = x.copy()\n",
        "        for i in range(x.shape[0]):\n",
        "            for j in range(x.shape[1]):\n",
        "                x[i, j] = max(x[i, j], 0)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_add(x, y):\n",
        "        assert len(x.shape) == 2 and x.shape == y.shape\n",
        "        x = x.copy()\n",
        "        for i in range(x.shape[0]):\n",
        "            for j in range(x.shape[1]):\n",
        "                x[i, j] += y[i, j]\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_dot(x, y):\n",
        "        assert len(x.shape) == 1 and len(y.shape) == 1\n",
        "        assert x.shape[0] == y.shape[0]\n",
        "        z = 0.\n",
        "        for i in range(x.shape[0]):\n",
        "            z += x[i] * y[i]\n",
        "        return z"
      ],
      "metadata": {
        "id": "FjL17ZVC5Iw-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next_batch(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ],
      "metadata": {
        "id": "XSAgrObR5KwV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientComputation:\n",
        "    @staticmethod\n",
        "    def compute_gradient(x):\n",
        "        x = tf.Variable(x)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y = 2 * x + 3\n",
        "        grad = tape.gradient(y, x)\n",
        "        return grad.numpy()\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_matrix_gradient(X, W, b):\n",
        "        X = tf.Variable(X)\n",
        "        W = tf.Variable(W)\n",
        "        b = tf.Variable(b)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y = tf.matmul(X, W) + b\n",
        "        grad_W, grad_b = tape.gradient(y, [W, b])\n",
        "        return grad_W.numpy(), grad_b.numpy()"
      ],
      "metadata": {
        "id": "GQNic0Q35MqF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader()\n",
        "data_loader.preprocess_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = data_loader.get_data()"
      ],
      "metadata": {
        "id": "qsUcFFwE5Qhv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_network = NeuralNetwork()\n",
        "trainer = Trainer(neural_network.get_model(), train_images, train_labels)\n",
        "trainer.train(epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsRxYFGf5SY2",
        "outputId": "c89a90ac-5142-4095-cad3-b343168df76a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8730 - loss: 0.4396\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9645 - loss: 0.1154\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0720\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9847 - loss: 0.0523\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(neural_network.get_model(), test_images, test_labels)\n",
        "evaluator.evaluate()\n",
        "evaluator.predict(index=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_PmVZs5Upu",
        "outputId": "1dfb9d72-5df2-46ca-cbe6-bd01eabe11ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0800\n",
            "Test Accuracy: 0.98\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Predicted Label: 7, Confidence: 1.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_op = MatrixOperations()\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "print(\"Relu applied:\", matrix_op.naive_relu(x)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9FGzj7m5Wrn",
        "outputId": "b460e269-da02-4107-8676-24dfddc744ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relu applied: [[0.68210867 0.26844333 0.02346306 0.89044372 0.48982586 0.39193264\n",
            "  0.80974622 0.84823082 0.03399332 0.59364864 0.36517648 0.25243852\n",
            "  0.98412398 0.09793063 0.56823322 0.02079737 0.31813958 0.07290921\n",
            "  0.49425955 0.72827252 0.8979239  0.8027512  0.79725841 0.9020959\n",
            "  0.21481667 0.85393007 0.43115246 0.27770735 0.11662055 0.00496846\n",
            "  0.45311272 0.08493915 0.80411333 0.11856711 0.58654525 0.32689178\n",
            "  0.30231045 0.22702521 0.56435989 0.91340063 0.25368822 0.59081105\n",
            "  0.50027662 0.19948799 0.6696955  0.04269278 0.92594544 0.94451136\n",
            "  0.81189181 0.76905306 0.17290508 0.65060295 0.0425853  0.00436092\n",
            "  0.25493984 0.20051494 0.47260625 0.610804   0.77183345 0.13231488\n",
            "  0.96410415 0.86537455 0.99227072 0.59900793 0.5997046  0.01192103\n",
            "  0.22846114 0.59305235 0.92663665 0.45049505 0.8978445  0.60853246\n",
            "  0.37912253 0.57271089 0.71688682 0.66898853 0.42815106 0.64871435\n",
            "  0.55088668 0.90435243 0.85254626 0.55329338 0.67092899 0.20998684\n",
            "  0.47818045 0.36032613 0.93704192 0.87284619 0.93952799 0.53196134\n",
            "  0.12821932 0.34020223 0.24075264 0.42823101 0.07442986 0.03490506\n",
            "  0.40397491 0.9486589  0.05887173 0.85821602]\n",
            " [0.33786912 0.98096057 0.23667329 0.71930524 0.14657692 0.47036421\n",
            "  0.83287882 0.16847761 0.56074537 0.29632135 0.31679917 0.24084003\n",
            "  0.51024711 0.40395484 0.68387349 0.89400192 0.57619216 0.398604\n",
            "  0.55848988 0.50159762 0.40734199 0.85736743 0.75520284 0.95823633\n",
            "  0.84979893 0.78013999 0.69824049 0.78141119 0.30597272 0.71922959\n",
            "  0.02567221 0.78557618 0.65947856 0.35502317 0.88460087 0.89922676\n",
            "  0.40716029 0.53800688 0.81233595 0.2138168  0.53435457 0.65757029\n",
            "  0.9468779  0.51029256 0.15520602 0.76964765 0.28544368 0.06453902\n",
            "  0.11381249 0.76392026 0.32898756 0.48948728 0.38958006 0.4291362\n",
            "  0.48336706 0.32241216 0.57777094 0.12122479 0.73352628 0.57012295\n",
            "  0.98630339 0.56443913 0.13468524 0.530546   0.15929103 0.65065886\n",
            "  0.24501044 0.93816423 0.46881471 0.99910911 0.37569982 0.93934002\n",
            "  0.10666691 0.1751025  0.60305838 0.32191212 0.16665123 0.50311866\n",
            "  0.02996789 0.26206672 0.74352195 0.09254232 0.87685134 0.39703784\n",
            "  0.70789498 0.61445388 0.99091712 0.44986607 0.90367154 0.60836546\n",
            "  0.60923223 0.61718909 0.50559497 0.53845393 0.28790589 0.52082672\n",
            "  0.70043795 0.51442929 0.70668863 0.16862063]\n",
            " [0.65920603 0.14696419 0.68425183 0.27086436 0.01670001 0.61953981\n",
            "  0.19041772 0.23344463 0.41568972 0.10257486 0.94297195 0.11601019\n",
            "  0.09001367 0.11196538 0.3226567  0.59244565 0.31550782 0.35982524\n",
            "  0.3033842  0.33584062 0.67531777 0.48701827 0.43027057 0.06823885\n",
            "  0.42682508 0.89647433 0.06591673 0.68907196 0.46528142 0.27189104\n",
            "  0.52840443 0.24572724 0.93684361 0.97896848 0.72982128 0.27671372\n",
            "  0.24693731 0.15111404 0.80896734 0.71446764 0.13305599 0.93367094\n",
            "  0.11895579 0.46384162 0.73162736 0.30652412 0.98290173 0.18746689\n",
            "  0.68582459 0.36079234 0.7803614  0.57853975 0.80739606 0.42479781\n",
            "  0.98803374 0.06648066 0.09449422 0.02993878 0.30832179 0.79090178\n",
            "  0.1437871  0.22386982 0.458136   0.11699025 0.86451996 0.17614627\n",
            "  0.24420178 0.92104283 0.20279754 0.31014562 0.17379205 0.46442789\n",
            "  0.78540217 0.29207646 0.14359509 0.22584136 0.37505109 0.68981719\n",
            "  0.92191795 0.23915719 0.36630173 0.51378567 0.71110388 0.83543305\n",
            "  0.76649121 0.06056444 0.80520964 0.42588692 0.69055759 0.66002288\n",
            "  0.42134897 0.75124582 0.4380145  0.08209226 0.98492035 0.02303417\n",
            "  0.13240431 0.44431538 0.63538348 0.91243682]\n",
            " [0.40137953 0.3345717  0.95448864 0.23478806 0.37519577 0.56200567\n",
            "  0.04864905 0.12489098 0.15242881 0.25948183 0.46303261 0.33155504\n",
            "  0.76318491 0.77902443 0.42538218 0.05827517 0.93937657 0.70216888\n",
            "  0.24982427 0.68489255 0.45196294 0.87916077 0.89265072 0.17075999\n",
            "  0.81086827 0.21751474 0.84177423 0.58037082 0.54734169 0.35152864\n",
            "  0.28769954 0.49917037 0.25976176 0.11236102 0.85266856 0.37148823\n",
            "  0.76882201 0.03948263 0.43807063 0.10625109 0.3642112  0.1463962\n",
            "  0.46060162 0.34509442 0.98105278 0.39364662 0.30795561 0.96933895\n",
            "  0.44611319 0.20774173 0.58182163 0.37337853 0.42403939 0.3907985\n",
            "  0.64831128 0.73080207 0.10986966 0.65610464 0.21021744 0.5323169\n",
            "  0.96739703 0.85111857 0.11523195 0.62943012 0.85089842 0.2002519\n",
            "  0.23534012 0.12211921 0.09305509 0.94726775 0.08908752 0.27394104\n",
            "  0.6530145  0.19728898 0.44303379 0.99808273 0.89114103 0.01675348\n",
            "  0.02908344 0.55258647 0.48077337 0.45477814 0.05941955 0.71430513\n",
            "  0.36005081 0.70768138 0.0018131  0.36176047 0.65052986 0.09924353\n",
            "  0.30551683 0.44510346 0.30553234 0.16000525 0.77294209 0.05843146\n",
            "  0.45380392 0.18445274 0.93789722 0.98395841]\n",
            " [0.48919164 0.81877893 0.93356242 0.17675901 0.40715672 0.30050363\n",
            "  0.95953121 0.57162361 0.12466907 0.93776793 0.11709193 0.71448631\n",
            "  0.37152421 0.5755511  0.33562622 0.87026513 0.28089951 0.1247847\n",
            "  0.01725488 0.81911701 0.91344862 0.37886938 0.88733589 0.99932374\n",
            "  0.65072892 0.64499109 0.11553775 0.75316505 0.27571365 0.24782532\n",
            "  0.83537313 0.43162031 0.98885582 0.39829648 0.96228614 0.49599955\n",
            "  0.06549091 0.08989619 0.98472406 0.42333391 0.36209611 0.49320311\n",
            "  0.85126763 0.18029436 0.43565075 0.33399107 0.04257984 0.04132053\n",
            "  0.69246049 0.59239158 0.38579415 0.30499527 0.11184361 0.92492909\n",
            "  0.66652547 0.47143783 0.0692684  0.39335101 0.40835753 0.29770272\n",
            "  0.99250861 0.29899615 0.23477953 0.4737249  0.28003752 0.24221457\n",
            "  0.52325646 0.41531043 0.21386781 0.19776938 0.1271505  0.77402141\n",
            "  0.14292557 0.06355082 0.84623997 0.4488233  0.86162184 0.77557505\n",
            "  0.94242111 0.75206862 0.22556549 0.50447879 0.27966569 0.13696452\n",
            "  0.80145796 0.30083483 0.015834   0.32378277 0.76228164 0.58342821\n",
            "  0.48877618 0.0708935  0.59302271 0.17782945 0.23402683 0.69386766\n",
            "  0.78897248 0.8445541  0.0822815  0.72074386]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_calc = GradientComputation()\n",
        "grad_x = grad_calc.compute_gradient(0.)\n",
        "print(\"Gradient of y = 2x + 3 w.r.t x:\", grad_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIeVZor5Y_2",
        "outputId": "79933b1c-5cf9-4fb4-8d25-d078e8606db2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of y = 2x + 3 w.r.t x: 2.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}